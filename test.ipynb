{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: data\\_RefSet\\ALPINE_C_424_Murguzur_RMSE1.16\\Xcal.csv.gz\n",
      "Header inference: True\n",
      "Delimiter inference: ;\n",
      "Data shape: (361, 2151)\n",
      "Data shape after dropna(all) cols: (361, 2151)\n",
      "Data shape after dropna(all) rows: (361, 2151)\n",
      "[[1.0522316  1.0564474 ]\n",
      " [0.91029036 0.9535987 ]]\n",
      "Loading file: data\\_RefSet\\ALPINE_C_424_Murguzur_RMSE1.16\\Xval.csv.gz\n",
      "Header inference: True\n",
      "Delimiter inference: ;\n",
      "Data shape: (63, 2151)\n",
      "Data shape after dropna(all) cols: (63, 2151)\n",
      "Data shape after dropna(all) rows: (63, 2151)\n",
      "[[0.7495551 0.788556 ]\n",
      " [0.8735659 0.895563 ]]\n",
      "Loading file: data\\_RefSet\\ALPINE_C_424_Murguzur_RMSE1.16\\Ycal.csv.gz\n",
      "Header inference: True\n",
      "Delimiter inference: 5\n",
      "Delimiter correction: \\n\n",
      "Data shape: (361, 1)\n",
      "Data shape after dropna(all) cols: (361, 1)\n",
      "Data shape after dropna(all) rows: (361, 1)\n",
      "[[50.047596]\n",
      " [43.892487]]\n",
      "Loading file: data\\_RefSet\\ALPINE_C_424_Murguzur_RMSE1.16\\Yval.csv.gz\n",
      "Header inference: True\n",
      "Delimiter inference: 8\n",
      "Delimiter correction: \\n\n",
      "Data shape: (63, 1)\n",
      "Data shape after dropna(all) cols: (63, 1)\n",
      "Data shape after dropna(all) rows: (63, 1)\n",
      "[[48.93384 ]\n",
      " [50.076485]]\n",
      "3a7184e32d05e07a ALPINE_C_424_Murguzur_RMSE1.16\n",
      "****************************************************************************************************\n",
      "Loading file: data\\_Raisin\\Raisin_Tavernier_830_GFratio\\Xcal.csv\n",
      "Header inference: False\n",
      "Delimiter inference: ;\n",
      "Data shape: (664, 125)\n",
      "Data shape after dropna(all) cols: (664, 125)\n",
      "Data shape after dropna(all) rows: (664, 125)\n",
      "Removing rows: [432, 434, 428, 438]\n",
      "Data shape after dropna(any) rows: (660, 125)\n",
      "[[0.2384144 0.2335801]\n",
      " [0.248429  0.2475333]]\n",
      "Loading file: data\\_Raisin\\Raisin_Tavernier_830_GFratio\\Xval.csv\n",
      "Header inference: False\n",
      "Delimiter inference: ;\n",
      "Data shape: (166, 125)\n",
      "Data shape after dropna(all) cols: (166, 125)\n",
      "Data shape after dropna(all) rows: (166, 125)\n",
      "[[0.2509339 0.2475901]\n",
      " [0.2625283 0.2588682]]\n",
      "Loading file: data\\_Raisin\\Raisin_Tavernier_830_GFratio\\Ycal.csv\n",
      "Header inference: False\n",
      "Delimiter inference: 3\n",
      "Delimiter correction: \\n\n",
      "Data shape: (664, 1)\n",
      "Data shape after dropna(all) cols: (664, 1)\n",
      "Data shape after dropna(all) rows: (664, 1)\n",
      "[[4.0473604]\n",
      " [3.65193  ]]\n",
      "Loading file: data\\_Raisin\\Raisin_Tavernier_830_GFratio\\Yval.csv\n",
      "Header inference: False\n",
      "Delimiter inference: 5\n",
      "Delimiter correction: \\n\n",
      "Data shape: (166, 1)\n",
      "Data shape after dropna(all) cols: (166, 1)\n",
      "Data shape after dropna(all) rows: (166, 1)\n",
      "[[2.7729297]\n",
      " [3.4805753]]\n",
      "e99ad05744d8b37 Raisin_Tavernier_830_GFratio\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# import pipeliner\n",
    "# import indexer\n",
    "from core.trainingjob import TrainingJob\n",
    "import core.datacache as datacache\n",
    "import core.indexer as indexer\n",
    "\n",
    "def generate_combinations(steps):\n",
    "    methods = []\n",
    "    for step in steps.values():\n",
    "        methods.append([(m, step[\"type\"]) for m in step['method']])\n",
    "    return list(product(*methods))\n",
    "\n",
    "\n",
    "# TRAINING\n",
    "training_config = {\n",
    "    \"seed\": [42],  # int\n",
    "    \"random_scope\": \"dataset\",  # str - [\"dataset\", \"global\", \"models\"]\n",
    "    \"paths\": [\"data/_RefSet/ALPINE_C_424_Murguzur_RMSE1.16\", \"data/_Raisin/Raisin_Tavernier_830_GFratio\"],  # List[str] - [path1, path2, ...]\n",
    "    \"indexation\": [],  # List[(Splitter, Dict)]  - [splitter, params] -> to create dataset indexes trees\n",
    "    \"pre_indexation\": {\n",
    "        \"step_1\": {\n",
    "            \"type\": \"filter\",\n",
    "            \"method\": [\"A\", \"B\", \"C\"],  # List[List[(TransformerMixin, Dict)]]\n",
    "        },\n",
    "        \"step_2\": {\n",
    "            \"type\": \"filter\",\n",
    "            \"method\": [\"D\", \"E\"],  # List[List[(TransformerMixin, Dict)]]\n",
    "        }\n",
    "    },\n",
    "    \"post_indexation\": {\n",
    "        \"step_1\": {\n",
    "            \"type\": \"augmentation\",\n",
    "            \"method\": [],  # List[List[(TransformerMixin, Dict)]]\n",
    "        },\n",
    "        \"step_2\": {\n",
    "            \"type\": \"preprocessing\",\n",
    "            \"method\": [],  # List[List[(TransformerMixin, Dict)]]\n",
    "        },\n",
    "    },\n",
    "    \"models\": [\n",
    "        [],  # List[(Estimator, Dict)]  - [estimator, params] -> to create sklearn pipeline\n",
    "    ],\n",
    "}\n",
    "\n",
    "# def \n",
    "\n",
    "def train(config):\n",
    "    for dataset_path in config[\"paths\"]:\n",
    "        # 1. Load data\n",
    "        dataset_uid, dataset_name, data = datacache.register_dataset(dataset_path)\n",
    "        print(dataset_uid, dataset_name)\n",
    "        print(\"*\"*100)\n",
    "        # # 2 .Filter data\n",
    "        # pre_indexation_steps = generate_combinations(config[\"pre_indexation\"])\n",
    "        # The above code is converting the data in a pandas DataFrame called `data` to numeric format\n",
    "        # using the `pd.to_numeric()` function. The `args=(\"coerce\",)` argument is used to convert any\n",
    "        # non-numeric values to NaN (Not a Number) values. This is useful for cleaning and preparing data\n",
    "        # for analysis.\n",
    "        # print(json.dumps(pre_indexation_steps, indent=4))\n",
    "        # # 3. Indexation\n",
    "        # if not pre_indexation_steps:\n",
    "        #     pre_indexation_steps = [None]\n",
    "\n",
    "        # for pre_indexation_step in pre_indexation_steps:\n",
    "        #     indexations = indexer.get(dataset, config[\"indexation\"], pre_indexation_step)\n",
    "        #     post_indexation_steps = generate_combinations(config[\"post_indexation\"])\n",
    "        #     runs = generate_combinations(indexations, post_indexation_steps, config[\"models\"])\n",
    "        #     for run in runs:\n",
    "        #         scheduler.add(run)\n",
    "\n",
    "train(training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import core.datacache as datacache\n",
    "import numpy as np\n",
    "\n",
    "data = datacache.load_csv(\"data/_RefSet/ALPINE_C_424_Murguzur_RMSE1.16/XCal.csv.gz\")\n",
    "\n",
    "# data.isna().any(axis=0)\n",
    "\n",
    "# hex(hash(str(data)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DECON_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
