{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Install dependencies not available on Google Collab.\n",
    "Collab provides numpy, pandas, sklearn, tensorflow, scipy, etc. (see requirements.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinard in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (0.9.5)\n",
      "Requirement already satisfied: pandas in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.3.4)\n",
      "Requirement already satisfied: scipy in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.7.3)\n",
      "Requirement already satisfied: PyWavelets in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.0.1)\n",
      "Requirement already satisfied: numpy in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.21.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (2.9.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pandas->pinard) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pandas->pinard) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn->pinard) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn->pinard) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (4.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.1.2)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (2.9.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.12)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (3.19.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.42.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (2.9.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.15.0)\n",
      "Requirement already satisfied: packaging in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (21.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (0.26.0)\n",
      "Requirement already satisfied: setuptools in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (47.1.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (14.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow->pinard) (0.37.0)\n",
      "Requirement already satisfied: cached-property in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from h5py>=2.9.0->tensorflow->pinard) (1.5.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (3.3.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from packaging->tensorflow->pinard) (3.0.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->pinard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->pinard) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->pinard) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->pinard) (3.1.1)\n",
      "Requirement already satisfied: scikeras in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: packaging>=0.21 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: importlib-metadata>=3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikeras) (5.0.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikeras) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from importlib-metadata>=3->scikeras) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from importlib-metadata>=3->scikeras) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from packaging>=0.21->scikeras) (3.0.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pinard\n",
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark details\n",
    "\n",
    "The results aggregate the combination of the following trainings configurations:\n",
    "- estimation configuration: [regression, classification]\n",
    "- datasets configurations: [Single Train, Cross validation with 5 folds and 2 repeats, Augmented Single Train]\n",
    "- preprocessing configuration: [flat spectrum, savgol, haar, [small set], [big_set]]\n",
    "- models: \n",
    "   - for all configuration: BACON, BACON-VG, DECON, PLS(components from 1 to 100), XGBoost, LW-PLS\n",
    "   - for single train + small_set : Stack > [ BACON, BACON-VG, DECON, PLS(components from 1 to 100), XGBoost, LW-PLS,\n",
    "   f_PLSRegression,f_AdaBoostRegressor,f_BaggingRegressor,f_ExtraTreesRegressor, f_GradientBoostingRegressor,f_RandomForestRegressor,\n",
    "   f_ARDRegression,f_BayesianRidge,f_ElasticNet,f_ElasticNetCV,f_HuberRegressor, f_LarsCV,f_LassoCV,f_Lasso,f_LassoLars,f_LassoLarsCV,\n",
    "   f_LassoLarsIC,f_LinearRegression,f_OrthogonalMatchingPursuit,f_OrthogonalMatchingPursuitCV, f_PassiveAggressiveRegressor,f_RANSACRegressor,\n",
    "   f_Ridge,f_RidgeCV,f_SGDRegressor,f_TheilSenRegressor,f_GaussianProcessRegressor,f_KNeighborsRegressor, f_Pipeline,f_MLPRegressor,f_LinearSVR,\n",
    "   f_NuSVR,f_SVR,f_DecisionTreeRegressor,f_ExtraTreeRegressor,f_KernelRidge,f_XGBRegressor]\n",
    "\n",
    "We perform training in 2 steps, (1) data transformation and (2) training because the sklearn pipeline does not use test data natively.\n",
    "To change with pinard update in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAST GPU RESET ####\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Benchmarking 288 runs.\n",
      "========== ALPINE_CALPINE_424_MURGUZUR ========== (272, 2151) (272, 1) (152, 2151) (152, 1)\n",
      "VGG_1D-NoSpl-NoCV-Fold_1(1)-NoAug-PP_2_-3462-31441_22-12-14_03-39-11 (272, 2151) (272, 1) (152, 2151, 2) (152, 1)\n",
      "--- Trainable: 1479969 - untrainable: 0.0 > 1479969.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 > RMSE: 17.768942 ( 1.36 ) - R²: -38.521912791516804  val_loss 0.78271484375\n",
      "Epoch: 1 > RMSE: 16.57503 ( 1.36 ) - R²: -33.389306668860605  val_loss 0.68115234375\n",
      "Epoch: 2 > RMSE: 11.534788 ( 1.36 ) - R²: -15.654595046752899  val_loss 0.329833984375\n",
      "Epoch: 3 > RMSE: 5.4681754 ( 1.36 ) - R²: -2.742826858598239  val_loss 0.0740966796875\n",
      "Epoch: 7 > RMSE: 3.540156 ( 1.36 ) - R²: -0.5687711427601276  val_loss 0.0310211181640625\n",
      "Epoch: 8 > RMSE: 3.497179 ( 1.36 ) - R²: -0.5309130497428247  val_loss 0.0303497314453125\n",
      "Saved best 0.0303 at epoch 8\n",
      "3.497179  ( 1.36 ) in 00:00:04\n",
      "xgboost.sklearn.XGBRegressor-NoSpl-NoCV-Fold_1(1)-NoAug-PP_2_-3462-31441_22-12-14_03-39-15 (272, 2151) (272, 1) (152, 4302) (152, 1)\n",
      "(self, *, objective: Union[str, Callable[[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'reg:squarederror', **kwargs: Any) -> None\n",
      "2.4760873  ( 1.36 ) in 00:00:02\n"
     ]
    }
   ],
   "source": [
    "## Browse path and launch benchmark for every folders\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from preprocessings import preprocessing_list\n",
    "\n",
    "from benchmark_loop import benchmark_dataset\n",
    "\n",
    "rootdir = Path('data/regression')\n",
    "folder_list = [f for f in rootdir.glob('**/*') if f.is_dir()]\n",
    "\n",
    "SEED = ord('D') + 31373\n",
    "\n",
    "import preprocessings\n",
    "import regressors\n",
    "import pinard.preprocessing as pp\n",
    "from pinard import augmentation, model_selection\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "import os.path\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules['pinard.preprocessing'], classname)\n",
    "\n",
    "# print(str_to_class('SavitzkyGolay'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset_list(path):\n",
    "    datasets = []\n",
    "    for r, d, _ in os.walk(path):\n",
    "        for folder in d:\n",
    "            path = os.path.join(r, folder)\n",
    "            if os.path.isdir(path):\n",
    "                if len(datasets) < 3:\n",
    "                    datasets.append(str(path))\n",
    "    return datasets\n",
    "\n",
    "split_configs = [\n",
    "    None,\n",
    "    {'test_size':None, 'method':\"random\", 'random_state':SEED},\n",
    "    {'test_size':None, 'method':\"stratified\", 'random_state':SEED, 'n_bins':5},\n",
    "    {'test_size':None, 'method':\"kennard_stone\", 'random_state':SEED, 'metric':\"euclidean\", 'pca_components':None},\n",
    "]\n",
    "\n",
    "augmentations = [\n",
    "    None,\n",
    "    [(2, augmentation.Rotate_Translate()),\n",
    "    (2, augmentation.Random_X_Operation()),\n",
    "    (1, augmentation.Random_Spline_Addition()),]\n",
    "]\n",
    "\n",
    "preprocessings_list = [\n",
    "    # preprocessings.id_preprocessing(),\n",
    "    [('haar', pp.Haar()), ('savgol', pp.SavitzkyGolay())],\n",
    "    preprocessings.decon_set(),\n",
    "]\n",
    "\n",
    "models = [\n",
    "    (regressors.ML_Regressor(XGBRegressor), {\"n_estimators\":200, \"max_depth\":50, \"seed\":SEED}),\n",
    "    (regressors.VGG_1D(), {'batch_size':256, 'epoch':10, 'verbose':0, 'optimizer':'Adam', 'loss':'mse'}),\n",
    "]\n",
    "\n",
    "cv_configs = [\n",
    "    None,\n",
    "    {'n_splits':3, 'n_repeats':1},\n",
    "    {'n_splits':5, 'n_repeats':2},\n",
    "]\n",
    "\n",
    "# import os\n",
    "folder = \"data/regression\"\n",
    "folders = get_dataset_list(folder)\n",
    "\n",
    "benchmark_size = len(folders) * len(split_configs) * len(cv_configs) * len(augmentations) * len(preprocessings_list) * len(models)\n",
    "print(\"Benchmarking\", benchmark_size, \"runs.\")\n",
    "\n",
    "# benchmark_dataset(folders, split_configs, cv_configs, augmentations, preprocessings_list, models, SEED,)\n",
    "benchmark_dataset([\"data/regression/ALPINE_Calpine_424_Murguzur_RMSE1.36\"], split_configs, cv_configs, augmentations, preprocessings_list, models, SEED,)\n",
    "\n",
    "\n",
    "# (preprocessing_list, nn_run, nn_cv, ml_single, ml_cv)\n",
    "\n",
    "# benchmark_dataset(\"data/regression/ALPINE_Calpine_424_Murguzur_RMSE1.36\", SEED, preprocessing_list(), 200)\n",
    "# benchmark_dataset(\"data/regression/Cassava_TBC_3556_Davrieux_RMSE1.02\", SEED, preprocessing_list(), augment=True)\n",
    "# benchmark_dataset(\"data/regression/LUCAS_SOCgrassland_4096_Nocita_RMSE7.2\", SEED, preprocessing_list(), 20, augment=False)\n",
    "# benchmark_dataset(\"data/regression/ALPINE_Calpine_424_Murguzur_RMSE1.36\", SEED, preprocessing_list(), 100, augment=False)\n",
    "# benchmark_dataset(\"data/regression/Cassava_TBC_3556_Davrieux_RMSE1.02\", SEED, preprocessing_list(), 20, augment=False)\n",
    "# benchmark_dataset(\"data/regression/Meat_Fa.33\", SEED, preprocessing_list(), 100, augment=False)\n",
    "\n",
    "# for folder in folder_list:\n",
    "    # # print(ord(str(folder)[17]), ord('A'), ord('M'))\n",
    "    # if ord(str(folder)[16]) < ord(\"L\") or ord(str(folder)[16]) > ord(\"M\"):\n",
    "    #     continue\n",
    "    # benchmark_dataset(folder, SEED, preprocessing_list(), 20, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_list = [\n",
    "    ({\"method\": \"random\", \"test_size\": 0.25, \"random_state\": 42}, 0),\n",
    "    (\n",
    "        {\n",
    "            \"method\": \"k_mean\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"canberra\",\n",
    "        },\n",
    "        1,\n",
    "    ),\n",
    "    (\n",
    "        {\n",
    "            \"pca_components\": 4,\n",
    "            \"method\": \"k_mean\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"canberra\",\n",
    "        },\n",
    "        2,\n",
    "    ),\n",
    "    ({\"method\": \"kennard_stone\", \"test_size\": 0.25, \"random_state\": 42}, 3),\n",
    "    (\n",
    "        {\n",
    "            \"method\": \"kennard_stone\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"correlation\",\n",
    "            \"pca_components\": 8,\n",
    "        },\n",
    "        4,\n",
    "    ),\n",
    "    (\n",
    "        {\n",
    "            \"method\": \"kennard_stone\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"correlation\",\n",
    "        },\n",
    "        5,\n",
    "    ),\n",
    "    ({\"method\": \"spxy\", \"test_size\": 0.25, \"random_state\": 42}, 6),\n",
    "    ({\"method\": \"spxy\", \"test_size\": 0.25, \"random_state\": 42, \"pca_components\": 2}, 7),\n",
    "    (\n",
    "        {\"method\": \"spxy\", \"test_size\": 0.25, \"random_state\": 42, \"metric\": \"canberra\"},\n",
    "        8,\n",
    "    ),\n",
    "    ({\"method\": \"stratified\", \"test_size\": 0.25, \"random_state\": 42}, 9),\n",
    "    ({\"method\": \"stratified\", \"test_size\": 0.25, \"random_state\": 42, \"n_bins\": 4}, 10),\n",
    "    ({\"method\": \"circular\", \"test_size\": 0.25, \"random_state\": 42}, 11),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6\n"
     ]
    }
   ],
   "source": [
    "# config = {\n",
    "#     'augmentation':[],\n",
    "#     'preprocessing':[],\n",
    "#     'runs':[\n",
    "#         {\n",
    "#             'model':'PLS',\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "\n",
    "# def parse_json(config, name=''):\n",
    "#     collection = []\n",
    "#     if isinstance(config, list):\n",
    "        \n",
    "#         pass\n",
    "#     elif isinstance(config, dict):\n",
    "#         pass\n",
    "    \n",
    "#     return name, collection\n",
    "a = [(5,6)]\n",
    "\n",
    "for b,c  in iter(a):\n",
    "    print(b,c )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynirsENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b09f6e5407ec4329146609a0cb08cbbe4720f97bb26598a93c421b663bd10d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
