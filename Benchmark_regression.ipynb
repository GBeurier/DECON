{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Install dependencies not available on Google Collab.\n",
    "Collab provides numpy, pandas, sklearn, tensorflow, scipy, etc. (see requirements.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinard in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (0.9.5)\n",
      "Requirement already satisfied: pandas in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.3.4)\n",
      "Requirement already satisfied: scipy in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.7.3)\n",
      "Requirement already satisfied: PyWavelets in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.0.1)\n",
      "Requirement already satisfied: numpy in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.21.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (2.9.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pandas->pinard) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pandas->pinard) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn->pinard) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn->pinard) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (4.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.1.2)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (2.9.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.12)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (3.19.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.42.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (2.9.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.15.0)\n",
      "Requirement already satisfied: packaging in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (21.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (0.26.0)\n",
      "Requirement already satisfied: setuptools in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (47.1.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (14.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow->pinard) (0.37.0)\n",
      "Requirement already satisfied: cached-property in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from h5py>=2.9.0->tensorflow->pinard) (1.5.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (3.3.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from packaging->tensorflow->pinard) (3.0.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->pinard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->pinard) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->pinard) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->pinard) (3.1.1)\n",
      "Requirement already satisfied: scikeras in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: packaging>=0.21 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: importlib-metadata>=3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikeras) (5.0.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikeras) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from importlib-metadata>=3->scikeras) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from importlib-metadata>=3->scikeras) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from packaging>=0.21->scikeras) (3.0.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pinard\n",
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark details\n",
    "\n",
    "The results aggregate the combination of the following trainings configurations:\n",
    "- estimation configuration: [regression, classification]\n",
    "- datasets configurations: [Single Train, Cross validation with 5 folds and 2 repeats, Augmented Single Train]\n",
    "- preprocessing configuration: [flat spectrum, savgol, haar, [small set], [big_set]]\n",
    "- models: \n",
    "   - for all configuration: BACON, BACON-VG, DECON, PLS(components from 1 to 100), XGBoost, LW-PLS\n",
    "   - for single train + small_set : Stack > [ BACON, BACON-VG, DECON, PLS(components from 1 to 100), XGBoost, LW-PLS,\n",
    "   f_PLSRegression,f_AdaBoostRegressor,f_BaggingRegressor,f_ExtraTreesRegressor, f_GradientBoostingRegressor,f_RandomForestRegressor,\n",
    "   f_ARDRegression,f_BayesianRidge,f_ElasticNet,f_ElasticNetCV,f_HuberRegressor, f_LarsCV,f_LassoCV,f_Lasso,f_LassoLars,f_LassoLarsCV,\n",
    "   f_LassoLarsIC,f_LinearRegression,f_OrthogonalMatchingPursuit,f_OrthogonalMatchingPursuitCV, f_PassiveAggressiveRegressor,f_RANSACRegressor,\n",
    "   f_Ridge,f_RidgeCV,f_SGDRegressor,f_TheilSenRegressor,f_GaussianProcessRegressor,f_KNeighborsRegressor, f_Pipeline,f_MLPRegressor,f_LinearSVR,\n",
    "   f_NuSVR,f_SVR,f_DecisionTreeRegressor,f_ExtraTreeRegressor,f_KernelRidge,f_XGBRegressor]\n",
    "\n",
    "We perform training in 2 steps, (1) data transformation and (2) training because the sklearn pipeline does not use test data natively.\n",
    "To change with pinard update in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAST GPU RESET ####\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29752\\3744753675.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data/regression\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mbenchmark_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_dataset_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessings_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSEED\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29752\\3744753675.py\u001b[0m in \u001b[0;36mget_dataset_list\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                 \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "## Browse path and launch benchmark for every folders\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from preprocessings import preprocessing_list\n",
    "\n",
    "from benchmark_loop import benchmark_dataset\n",
    "\n",
    "rootdir = Path('data/regression')\n",
    "folder_list = [f for f in rootdir.glob('**/*') if f.is_dir()]\n",
    "\n",
    "SEED = ord('D') + 31373\n",
    "\n",
    "import preprocessings\n",
    "import regressors\n",
    "import pinard.preprocessing as pp\n",
    "from pinard import augmentation, model_selection\n",
    "\n",
    "import sys\n",
    "import os.path\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules['pinard.preprocessing'], classname)\n",
    "\n",
    "# print(str_to_class('SavitzkyGolay'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset_list(path):\n",
    "    datasets = []\n",
    "    for r, d, _ in os.walk(path):\n",
    "        for folder in d:\n",
    "            path = os.path.join(r, folder)\n",
    "            if os.path.isdir(path):\n",
    "                datasets.append(str(path))\n",
    "    return datasets\n",
    "\n",
    "split_list = [\n",
    "    None,\n",
    "    {'test_size':None, 'method':\"random\", 'random_state':SEED},\n",
    "    {'test_size':None, 'method':\"stratified\", 'random_state':SEED, 'n_bins':5},\n",
    "    {'test_size':None, 'method':\"kennard_stone\", 'random_state':SEED, 'metric':\"euclidean\", 'pca_components':None},\n",
    "]\n",
    "\n",
    "augmentations = [\n",
    "    None,\n",
    "    [(augmentation.Rotate_Translate(), 2),\n",
    "    (augmentation.Random_X_Operation(), 2),\n",
    "    (augmentation.Random_Spline_Addition(), 1),]\n",
    "]\n",
    "\n",
    "preprocessings_list = [\n",
    "    preprocessings.id_preprocessing(),\n",
    "    [pp.Haar(), pp.SavitzkyGolay()],\n",
    "    preprocessings.dumb_set(),\n",
    "]\n",
    "\n",
    "models = [\n",
    "    (regressors.VGG_1D(), {'batch_size':256, 'epoch':2000, 'verbose':0, 'optimizer':'Adam', 'loss':'mse'}),\n",
    "    # (regressors.SKLEARN(), {'batch_size' = 256, 'epoch'=2000, 'optimizer'='Adam', 'loss'='mse'}),\n",
    "]\n",
    "\n",
    "training_config = {\n",
    "    #\"splitting\":\"random\",\n",
    "    #\"splitting_ratio\":\"0.2\",\n",
    "    #\"cross_validation\" = \"stratified_kfold\",\n",
    "    #\"cross_validation_size = (4,2)\n",
    "}\n",
    "\n",
    "# import os\n",
    "folder = \"data/regression\"\n",
    "\n",
    "benchmark_dataset(get_dataset_list(folder), split_list, training_config, augmentations, preprocessings_list, models, SEED,)\n",
    "\n",
    "\n",
    "\n",
    "# (preprocessing_list, nn_run, nn_cv, ml_single, ml_cv)\n",
    "\n",
    "# benchmark_dataset(\"data/regression/ALPINE_Calpine_424_Murguzur_RMSE1.36\", SEED, preprocessing_list(), 200)\n",
    "# benchmark_dataset(\"data/regression/Cassava_TBC_3556_Davrieux_RMSE1.02\", SEED, preprocessing_list(), augment=True)\n",
    "# benchmark_dataset(\"data/regression/LUCAS_SOCgrassland_4096_Nocita_RMSE7.2\", SEED, preprocessing_list(), 20, augment=False)\n",
    "# benchmark_dataset(\"data/regression/ALPINE_Calpine_424_Murguzur_RMSE1.36\", SEED, preprocessing_list(), 100, augment=False)\n",
    "# benchmark_dataset(\"data/regression/Cassava_TBC_3556_Davrieux_RMSE1.02\", SEED, preprocessing_list(), 20, augment=False)\n",
    "# benchmark_dataset(\"data/regression/Meat_FatE1_215_Borggaard_RMSE2.33\", SEED, preprocessing_list(), 100, augment=False)\n",
    "\n",
    "# for folder in folder_list:\n",
    "    # # print(ord(str(folder)[17]), ord('A'), ord('M'))\n",
    "    # if ord(str(folder)[16]) < ord(\"L\") or ord(str(folder)[16]) > ord(\"M\"):\n",
    "    #     continue\n",
    "    # benchmark_dataset(folder, SEED, preprocessing_list(), 20, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_list = [\n",
    "    ({\"method\": \"random\", \"test_size\": 0.25, \"random_state\": 42}, 0),\n",
    "    (\n",
    "        {\n",
    "            \"method\": \"k_mean\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"canberra\",\n",
    "        },\n",
    "        1,\n",
    "    ),\n",
    "    (\n",
    "        {\n",
    "            \"pca_components\": 4,\n",
    "            \"method\": \"k_mean\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"canberra\",\n",
    "        },\n",
    "        2,\n",
    "    ),\n",
    "    ({\"method\": \"kennard_stone\", \"test_size\": 0.25, \"random_state\": 42}, 3),\n",
    "    (\n",
    "        {\n",
    "            \"method\": \"kennard_stone\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"correlation\",\n",
    "            \"pca_components\": 8,\n",
    "        },\n",
    "        4,\n",
    "    ),\n",
    "    (\n",
    "        {\n",
    "            \"method\": \"kennard_stone\",\n",
    "            \"test_size\": 0.25,\n",
    "            \"random_state\": 42,\n",
    "            \"metric\": \"correlation\",\n",
    "        },\n",
    "        5,\n",
    "    ),\n",
    "    ({\"method\": \"spxy\", \"test_size\": 0.25, \"random_state\": 42}, 6),\n",
    "    ({\"method\": \"spxy\", \"test_size\": 0.25, \"random_state\": 42, \"pca_components\": 2}, 7),\n",
    "    (\n",
    "        {\"method\": \"spxy\", \"test_size\": 0.25, \"random_state\": 42, \"metric\": \"canberra\"},\n",
    "        8,\n",
    "    ),\n",
    "    ({\"method\": \"stratified\", \"test_size\": 0.25, \"random_state\": 42}, 9),\n",
    "    ({\"method\": \"stratified\", \"test_size\": 0.25, \"random_state\": 42, \"n_bins\": 4}, 10),\n",
    "    ({\"method\": \"circular\", \"test_size\": 0.25, \"random_state\": 42}, 11),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config = {\n",
    "#     'augmentation':[],\n",
    "#     'preprocessing':[],\n",
    "#     'runs':[\n",
    "#         {\n",
    "#             'model':'PLS',\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "\n",
    "# def parse_json(config, name=''):\n",
    "#     collection = []\n",
    "#     if isinstance(config, list):\n",
    "        \n",
    "#         pass\n",
    "#     elif isinstance(config, dict):\n",
    "#         pass\n",
    "    \n",
    "#     return name, collection\n",
    "a = [5,6]\n",
    "next(iter(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('PyNIRS_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3c3249a294db370905b327c25644ce18610bfebb370223cf3414a9c437db486"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
