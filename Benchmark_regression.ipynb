{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Install dependencies not available on Google Collab.\n",
    "Collab provides numpy, pandas, sklearn, tensorflow, scipy, etc. (see requirements.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of regressors failed: Traceback (most recent call last):\n",
      "  File \"d:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"d:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"d:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"d:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 317, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"d:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 278, in update_instances\n",
      "    for ref in refs:\n",
      "KeyboardInterrupt\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinard in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (0.9.5)\n",
      "Requirement already satisfied: scikit-learn in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.0.1)\n",
      "Requirement already satisfied: pandas in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.3.4)\n",
      "Requirement already satisfied: tensorflow in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (2.9.1)\n",
      "Requirement already satisfied: PyWavelets in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.2.0)\n",
      "Requirement already satisfied: scipy in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.7.3)\n",
      "Requirement already satisfied: numpy in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pinard) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pandas->pinard) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pandas->pinard) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn->pinard) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn->pinard) (3.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.1.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (3.19.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (0.26.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (3.1.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (14.0.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (0.2.0)\n",
      "Requirement already satisfied: packaging in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (21.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.12)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (2.9.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.42.0)\n",
      "Requirement already satisfied: setuptools in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (47.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (4.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorflow->pinard) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow->pinard) (0.37.0)\n",
      "Requirement already satisfied: cached-property in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from h5py>=2.9.0->tensorflow->pinard) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow->pinard) (1.35.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from packaging->tensorflow->pinard) (3.0.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->pinard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->pinard) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->pinard) (1.26.7)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow->pinard) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->pinard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->pinard) (3.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: importlib-metadata>=3 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikeras) (5.0.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikeras) (1.0.1)\n",
      "Requirement already satisfied: packaging>=0.21 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from importlib-metadata>=3->scikeras) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from importlib-metadata>=3->scikeras) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from packaging>=0.21->scikeras) (3.0.6)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\workspace\\ml\\pynirsenv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\workspace\\ml\\pynirsenv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pinard\n",
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark details\n",
    "\n",
    "The results aggregate the combination of the following trainings configurations:\n",
    "- estimation configuration: [regression, classification]\n",
    "- datasets configurations: [Single Train, Cross validation with 5 folds and 2 repeats, Augmented Single Train]\n",
    "- preprocessing configuration: [flat spectrum, savgol, haar, [small set], [big_set]]\n",
    "- models: \n",
    "   - for all configuration: BACON, BACON-VG, DECON, PLS(components from 1 to 100), XGBoost, LW-PLS\n",
    "   - for single train + small_set : Stack > [ BACON, BACON-VG, DECON, PLS(components from 1 to 100), XGBoost, LW-PLS,\n",
    "   f_PLSRegression,f_AdaBoostRegressor,f_BaggingRegressor,f_ExtraTreesRegressor, f_GradientBoostingRegressor,f_RandomForestRegressor,\n",
    "   f_ARDRegression,f_BayesianRidge,f_ElasticNet,f_ElasticNetCV,f_HuberRegressor, f_LarsCV,f_LassoCV,f_Lasso,f_LassoLars,f_LassoLarsCV,\n",
    "   f_LassoLarsIC,f_LinearRegression,f_OrthogonalMatchingPursuit,f_OrthogonalMatchingPursuitCV, f_PassiveAggressiveRegressor,f_RANSACRegressor,\n",
    "   f_Ridge,f_RidgeCV,f_SGDRegressor,f_TheilSenRegressor,f_GaussianProcessRegressor,f_KNeighborsRegressor, f_Pipeline,f_MLPRegressor,f_LinearSVR,\n",
    "   f_NuSVR,f_SVR,f_DecisionTreeRegressor,f_ExtraTreeRegressor,f_KernelRidge,f_XGBRegressor]\n",
    "\n",
    "We perform training in 2 steps, (1) data transformation and (2) training because the sklearn pipeline does not use test data natively.\n",
    "To change with pinard update in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAST GPU RESET ####\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "['data/regression\\\\ALPINE_C_424_Murguzur_RMSE1.16', 'data/regression\\\\Cassava_TBC_3393_Sanchez_RMSE1.12', 'data/regression\\\\LUCAS_SOCgrassland_4096_Nocita_RMSE7.2', 'data/regression\\\\Meat_Fat_215_Borggaard_RMSE0.65']\n",
      "Benchmarking 4 runs.\n",
      "========== ALPINE_C_424_MURGUZUR_RMSE1.16 ( resample 2048 ) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Workspace\\ML\\DECON\\data.py:81: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  X_train, y_train = load_csv(files[0], files[1], x_hdr=None, y_hdr=None, sep=\";\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing X: [0 0 0 ... 0 0 0]\n",
      "========== (361, 2048) (361, 1) (63, 2048) (63, 1)\n",
      "ResNetV2--NoSpl-NoCV-Fold_1(1)-NoAug-PP_22_23906-31441-23-02-08_16-21-21 (361, 2048) (361, 1) (63, 2048, 22) (63, 1)\n",
      "--- Trainable: 1432061 - untrainable: 12908 > 1444969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** (63, 2048) (63, 1) (63, 1)\n",
      "Epoch: 0 > RMSE: 75.098  ( -1 | None ) - R²: -1152.1123005585287  val_loss 10.078125\n",
      "********** (63, 2048) (63, 1) (63, 1)625\n",
      "Epoch: 1 > RMSE: 48.117783  ( -1 | None ) - R²: -472.3976925462145  val_loss 4.140625\n",
      "********** (63, 2048) (63, 1) (63, 1)90625\n",
      "Epoch: 2 > RMSE: 44.809498  ( -1 | None ) - R²: -409.5396022251484  val_loss 3.587890625\n",
      "********** (63, 2048) (63, 1)   2.294921875(63, 1)\n",
      "Epoch: 3 > RMSE: 35.829994  ( -1 | None ) - R²: -261.4873422058601  val_loss 2.294921875\n",
      "********** (63, 2048) (63, 1) (63, 1)9453125\n",
      "Epoch: 4 > RMSE: 14.734008  ( -1 | None ) - R²: -43.387093704555284  val_loss 0.387939453125\n",
      "********** (63, 2048) (63, 1) (63, 1)833984375\n",
      "Epoch: 5 > RMSE: 13.58573  ( -1 | None ) - R²: -36.738170051368584  val_loss 0.329833984375\n",
      "********** (63, 2048) (63, 1) (63, 1)82421875\n",
      "Epoch: 7 > RMSE: 13.370371  ( -1 | None ) - R²: -35.55121184307552  val_loss 0.31982421875\n",
      "********** (63, 2048) (63, 1) (63, 1)6328125\n",
      "Epoch: 8 > RMSE: 11.473771  ( -1 | None ) - R²: -25.91703498017988  val_loss 0.2354736328125\n",
      "********** (63, 2048) (63, 1)   0.202880859375(63, 1)\n",
      "Epoch: 11 > RMSE: 10.6449175  ( -1 | None ) - R²: -22.168581254842234  val_loss 0.202880859375\n",
      "********** (63, 2048) (63, 1) (63, 1)19921875\n",
      "Epoch: 13 > RMSE: 10.018202  ( -1 | None ) - R²: -19.520808842024437  val_loss 0.17919921875\n",
      "********** (63, 2048) (63, 1) (63, 1)574218755\n",
      "Epoch: 15 > RMSE: 9.560484  ( -1 | None ) - R²: -17.68850742731108  val_loss 0.16357421875\n",
      "********** (63, 2048) (63, 1) (63, 1)6875\n",
      "Epoch: 16 > RMSE: 9.45583  ( -1 | None ) - R²: -17.281597307378135  val_loss 0.15966796875\n",
      "********** (63, 2048) (63, 1) (63, 1)9208984375\n",
      "Epoch: 17 > RMSE: 8.979792  ( -1 | None ) - R²: -15.487220136961298  val_loss 0.1439208984375\n",
      "********** (63, 2048) (63, 1) (63, 1)44091796875\n",
      "Epoch: 19 > RMSE: 7.9941635  ( -1 | None ) - R²: -12.066549554016968  val_loss 0.11444091796875\n",
      "********** (63, 2048) (63, 1) (63, 1)1777343755\n",
      "Epoch: 25 > RMSE: 7.7507987  ( -1 | None ) - R²: -11.283095087253098  val_loss 0.107177734375\n",
      "********** (63, 2048) (63, 1) (63, 1)3828125\n",
      "Epoch: 26 > RMSE: 7.2687063  ( -1 | None ) - R²: -9.802621300321414  val_loss 0.09423828125\n",
      "********** (63, 2048) (63, 1) (63, 1)26953125125\n",
      "Epoch: 28 > RMSE: 7.0157456  ( -1 | None ) - R²: -9.063813315419935  val_loss 0.0880126953125\n",
      "********** (63, 2048) (63, 1) (63, 1)31250234375\n",
      "Epoch: 32 > RMSE: 6.503128  ( -1 | None ) - R²: -7.646881939955261  val_loss 0.075439453125\n",
      "********** (63, 2048) (63, 1) (63, 1)70214843755\n",
      "Epoch: 37 > RMSE: 6.236745  ( -1 | None ) - R²: -6.952997253986649  val_loss 0.0697021484375\n",
      "********** (63, 2048) (63, 1) (63, 1)56253515625\n",
      "Epoch: 40 > RMSE: 5.956167  ( -1 | None ) - R²: -6.253516872732637  val_loss 0.0634765625\n",
      "********** (63, 2048) (63, 1) (63, 1)9833984375\n",
      "Epoch: 47 > RMSE: 5.6967564  ( -1 | None ) - R²: -5.635447832883292  val_loss 0.0579833984375\n",
      "********** (63, 2048) (63, 1) (63, 1)276611328125\n",
      "Epoch: 49 > RMSE: 5.4036794  ( -1 | None ) - R²: -4.970270749017978  val_loss 0.052276611328125\n",
      "********** (63, 2048) (63, 1) (63, 1)92382812525\n",
      "Epoch: 56 > RMSE: 5.251576  ( -1 | None ) - R²: -4.638897553415233  val_loss 0.049346923828125\n",
      "********** (63, 2048) (63, 1) (63, 1)95996093755\n",
      "Epoch: 60 > RMSE: 4.8416433  ( -1 | None ) - R²: -3.7929238894736885  val_loss 0.041839599609375\n",
      "********** (63, 2048) (63, 1) (63, 1)363769531255\n",
      "Epoch: 62 > RMSE: 4.1683927  ( -1 | None ) - R²: -2.552647274581278  val_loss 0.031036376953125\n",
      "********** (63, 2048) (63, 1) (63, 1)590332031255\n",
      "Epoch: 66 > RMSE: 3.4879858  ( -1 | None ) - R²: -1.4875072848611475  val_loss 0.021759033203125\n",
      "********** (63, 2048) (63, 1) (63, 1)154541015625\n",
      "Epoch: 70 > RMSE: 3.1490211  ( -1 | None ) - R²: -1.0275241124005259  val_loss 0.0177154541015625\n",
      "********** (63, 2048) (63, 1) (63, 1)34924316406255\n",
      "Epoch: 147 > RMSE: 3.1174245  ( -1 | None ) - R²: -0.9870409121922887  val_loss 0.0173492431640625\n",
      "********** (63, 2048) (63, 1) (63, 1)304443359375\n",
      "Epoch: 148 > RMSE: 3.0686216  ( -1 | None ) - R²: -0.9253137638224767  val_loss 0.0168304443359375\n",
      "********** (63, 2048) (63, 1) (63, 1)7999267578125\n",
      "Epoch: 151 > RMSE: 3.0643964  ( -1 | None ) - R²: -0.9200156819077872  val_loss 0.0167999267578125\n",
      "********** (63, 2048) (63, 1) (63, 1)07763671875\n",
      "Epoch: 152 > RMSE: 2.9615593  ( -1 | None ) - R²: -0.7933116422815496  val_loss 0.0156707763671875\n",
      "********** (63, 2048) (63, 1) (63, 1)19012451171875\n",
      "Epoch: 155 > RMSE: 2.9184325  ( -1 | None ) - R²: -0.7414626739731898  val_loss 0.01519012451171875\n",
      "********** (63, 2048) (63, 1) (63, 1)1274414062575\n",
      "Epoch: 164 > RMSE: 2.8270166  ( -1 | None ) - R²: -0.6340735587770361  val_loss 0.014312744140625\n",
      "********** (63, 2048) (63, 1) (63, 1)16070556640625\n",
      "Epoch: 167 > RMSE: 2.71521  ( -1 | None ) - R²: -0.5073764070771685  val_loss 0.01316070556640625\n",
      "********** (63, 2048) (63, 1) (63, 1)3901367187575\n",
      "Epoch: 170 > RMSE: 2.6320524  ( -1 | None ) - R²: -0.4164588630417785  val_loss 0.01239013671875\n",
      "********** (63, 2048) (63, 1) (63, 1)77880859375625\n",
      "Epoch: 176 > RMSE: 2.5910592  ( -1 | None ) - R²: -0.37268067049432596  val_loss 0.01198577880859375\n",
      "********** (63, 2048) (63, 1) (63, 1)32965087890625\n",
      "Epoch: 177 > RMSE: 2.5196254  ( -1 | None ) - R²: -0.29803624543688856  val_loss 0.01132965087890625\n",
      "********** (63, 2048) (63, 1) (63, 1)13946533203125\n",
      "Epoch: 181 > RMSE: 2.3817341  ( -1 | None ) - R²: -0.15984897703558953  val_loss 0.01013946533203125\n",
      "********** (63, 2048) (63, 1) (63, 1)83337402343755\n",
      "Epoch: 196 > RMSE: 2.3026183  ( -1 | None ) - R²: -0.0840735544647424  val_loss 0.00948333740234375\n",
      "********** (63, 2048) (63, 1) (63, 1)3994140625575\n",
      "Epoch: 199 > RMSE: 2.294434  ( -1 | None ) - R²: -0.07638113715213435  val_loss 0.0093994140625\n",
      "********** (63, 2048) (63, 1) (63, 1)94165039062525\n",
      "Epoch: 207 > RMSE: 2.2381492  ( -1 | None ) - R²: -0.024219352425614904  val_loss 0.008941650390625\n",
      "********** (63, 2048) 90624  -  0.00865936279296875(63, 1) (63, 1)\n",
      "Epoch: 210 > RMSE: 2.2020023  ( -1 | None ) - R²: 0.008596544460132804  val_loss 0.00865936279296875\n",
      "Saved best 0.0087 at epoch 210-  0.01081848144531255\n",
      "Epoch 511: early stopping\n",
      "2.2020023  ( -1 | None ) in 00:04:09\n",
      "========== CASSAVA_TBC_3393_SANCHEZ_RMSE1.12 ( resample 2048 ) "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Workspace\\ML\\DECON\\data.py:81: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  X_train, y_train = load_csv(files[0], files[1], x_hdr=None, y_hdr=None, sep=\";\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing X: [0 0 0 ... 0 0 0]\n",
      "========== (1823, 2048) (1823, 1) (1270, 2048) (1270, 1)\n",
      "ResNetV2--NoSpl-NoCV-Fold_1(1)-NoAug-PP_22_23906-31441-23-02-08_16-25-37 (1823, 2048) (1823, 1) (1270, 2048, 22) (1270, 1)\n",
      "--- Trainable: 1432061 - untrainable: 12908 > 1444969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run TensorDataset: Dst tensor is not initialized. [Op:TensorDataset]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25796/120445209.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m \u001b[0mbenchmark_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_configs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_configs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessings_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSEED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresampling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resample'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#bins=5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;31m# benchmark_dataset(folders, split_configs, cv_configs, augmentations, preprocessings_list, models, SEED, resampling='crop', resample_size=2150)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\DECON\\benchmark_loop.py\u001b[0m in \u001b[0;36mbenchmark_dataset\u001b[1;34m(dataset_list, split_configs, cv_configs, augmentations, preprocessings, models, SEED, bins, resampling, resample_size)\u001b[0m\n\u001b[0;32m    335\u001b[0m                                 \u001b[0mtransformers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_scaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformer_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m                                 \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_RMSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_current_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscretizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mname_cv\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"NoCV\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m                                     \u001b[1;32mif\u001b[0m \u001b[0mrun_key\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv_predictions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\DECON\\benchmark_loop.py\u001b[0m in \u001b[0;36mevaluate_pipeline\u001b[1;34m(desc, model_name, data, transformers, target_RMSE, best_current_model, discretizer)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mcurrent_y_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mcurrent_y_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m     \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[1;31m# Evaluate estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\sklearn\\compose\\_target.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"feature_names_in_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    765\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m         )\n\u001b[0;32m    769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m             \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m         )\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\scikeras\\wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[1;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"history_\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Workspace\\ML\\pynirsENV\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7164\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run TensorDataset: Dst tensor is not initialized. [Op:TensorDataset]"
     ]
    }
   ],
   "source": [
    "## Browse path and launch benchmark for every folders\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from preprocessings import preprocessing_list\n",
    "\n",
    "from benchmark_loop import benchmark_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "rootdir = Path('data/regression')\n",
    "folder_list = [f for f in rootdir.glob('**/*') if f.is_dir()]\n",
    "\n",
    "SEED = ord('D') + 31373\n",
    "\n",
    "# tf.keras.utils.set_random_seed(SEED)\n",
    "# tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "\n",
    "import preprocessings\n",
    "import regressors\n",
    "import pinard.preprocessing as pp\n",
    "from pinard import augmentation, model_selection\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "import os.path\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules['pinard.preprocessing'], classname)\n",
    "\n",
    "# print(str_to_class('SavitzkyGolay'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset_list(path):\n",
    "    datasets = []\n",
    "    for r, d, _ in os.walk(path):\n",
    "        for folder in d:\n",
    "            path = os.path.join(r, folder)\n",
    "            if os.path.isdir(path):\n",
    "                # if len(datasets) < 3:\n",
    "                datasets.append(str(path))\n",
    "    return datasets\n",
    "\n",
    "split_configs = [\n",
    "    None,\n",
    "    # {'test_size':None, 'method':\"random\", 'random_state':SEED},\n",
    "    # {'test_size':None, 'method':\"stratified\", 'random_state':SEED, 'n_bins':5},\n",
    "    # {'test_size':0.25, 'method':\"spxy\", 'random_state':SEED, 'metric':\"euclidean\", 'pca_components':250},\n",
    "]\n",
    "\n",
    "augmentations = [\n",
    "    None,\n",
    "    # [(6, augmentation.Rotate_Translate())],\n",
    "    # [(3, augmentation.Rotate_Translate()),(2, augmentation.Random_X_Operation()),(1, augmentation.Random_Spline_Addition()),],\n",
    "    # [(3, augmentation.Rotate_Translate()),(2, augmentation.Random_X_Operation()),(2, augmentation.Random_Spline_Addition()),]\n",
    "]\n",
    "\n",
    "preprocessings_list = [\n",
    "    # None,\n",
    "    # preprocessings.id_preprocessing(),\n",
    "    [(\"id\", pp.IdentityTransformer()), ('haar', pp.Haar()), ('savgol', pp.SavitzkyGolay())],\n",
    "    # preprocessings.decon_set(),\n",
    "    # preprocessings.bacon_set(),\n",
    "    # preprocessings.small_set(),\n",
    "    # preprocessings.transf_set(),\n",
    "    # preprocessings.optimal_set_2D(),\n",
    "    # preprocessings.fat_set(),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "cv_configs = [\n",
    "    None,\n",
    "    # {'n_splits':5, 'n_repeats':4},\n",
    "    # {'n_splits':4, 'n_repeats':2},\n",
    "    # {'n_splits':3, 'n_repeats':1},\n",
    "]\n",
    "\n",
    "# import os\n",
    "folder = \"data/regression\"\n",
    "folders = get_dataset_list(folder)\n",
    "print(folders)\n",
    "# folders = [\"data/regression/Cassava_TBC_3556_Davrieux_RMSE1.02\"]\n",
    "\n",
    "len_cv_configs = 0\n",
    "for c in cv_configs:\n",
    "    if c == None:\n",
    "        len_cv_configs += 1\n",
    "    else:\n",
    "        len_cv_configs += (c['n_splits'] * c['n_repeats'])\n",
    "\n",
    "models = [\n",
    "    # (regressors.ML_Regressor(XGBRegressor), {\"n_estimators\":200, \"max_depth\":50, \"seed\":SEED}),\n",
    "    # (regressors.ML_Regressor(PLSRegression), {\"n_components\":50}),\n",
    "    # (regressors.Transformer_NIRS(), {'batch_size':500, 'epoch':10000, 'verbose':0, 'patience':1000, 'optimizer':'adam', 'loss':'mse'}),\n",
    "    # (regressors.Decon_SepPo(), {'batch_size':50, 'epoch':10000, 'verbose':0, 'patience':1000, 'optimizer':'adam', 'loss':'mse'}),\n",
    "    # (regressors.FFT_Conv(), {'batch_size':500, 'epoch':20000, 'verbose':0, 'patience':1000, 'optimizer':'adam', 'loss':'mse'}),\n",
    "    # (regressors.Decon_Sep(), {'batch_size':1000, 'epoch':20000, 'verbose':0, 'patience':400, 'optimizer':'adam', 'loss':'mse'}),\n",
    "    (regressors.ResNetV2(), {'batch_size':200, 'epoch':20000, 'verbose':0, 'patience':300, 'optimizer':'adam', 'loss':'mse'}),\n",
    "    # (regressors.MLP(), {'batch_size':1000, 'epoch':20000, 'verbose':0, 'patience':2000, 'optimizer':'adam', 'loss':'mse'}),\n",
    "    # (regressors.CONV_LSTM(), {'batch_size':1000, 'epoch':20000, 'verbose':0, 'patience':2000, 'optimizer':'adam', 'loss':'mse'}),\n",
    "    # (regressors.XCeption1D(), {'batch_size':500, 'epoch':10000, 'verbose':0, 'patience':1200, 'optimizer':'adam', 'loss':'mse'}),\n",
    "    # (regressors.Transformer(), {'batch_size':10, 'epoch':300, 'verbose':0, 'patience':30, 'optimizer':'Adam', 'loss':'mse'}),\n",
    "]\n",
    "\n",
    "benchmark_size = len(folders) * len(split_configs) * len_cv_configs * len(augmentations) * len(preprocessings_list) * len(models)\n",
    "print(\"Benchmarking\", benchmark_size, \"runs.\")\n",
    "\n",
    "\n",
    "benchmark_dataset(folders, split_configs, cv_configs, augmentations, preprocessings_list, models, SEED, resampling='resample', resample_size=2048) #bins=5)\n",
    "# benchmark_dataset(folders, split_configs, cv_configs, augmentations, preprocessings_list, models, SEED, resampling='crop', resample_size=2150)\n",
    "\n",
    "\n",
    "# for folder in folder_list:\n",
    "    # # print(ord(str(folder)[17]), ord('A'), ord('M'))\n",
    "    # if ord(str(folder)[16]) < ord(\"L\") or ord(str(folder)[16]) > ord(\"M\"):\n",
    "    #     continue\n",
    "    # benchmark_dataset(folder, SEED, preprocessing_list(), 20, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import numpy as np\n",
    "y_train = np.array([0,1,2,2.5,3,3.5,6,8,20]).reshape(-1,1)\n",
    "bins = 4\n",
    "discretizer = KBinsDiscretizer(n_bins=bins, encode='onehot-dense', strategy='uniform')\n",
    "discretizer.fit(y_train)\n",
    "tt = discretizer.transform(y_train)\n",
    "print(tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "def plot_regression_results(ax, y_true, y_pred, title, scores, elapsed_time):\n",
    "    \"\"\"Scatter plot of the predicted vs true targets.\"\"\"\n",
    "    ax.plot(\n",
    "        [y_true.min(), y_true.max()], [y_true.min(), y_true.max()], \"--r\", linewidth=2\n",
    "    )\n",
    "    ax.scatter(y_true, y_pred, alpha=0.2)\n",
    "\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines[\"left\"].set_position((\"outward\", 10))\n",
    "    ax.spines[\"bottom\"].set_position((\"outward\", 10))\n",
    "    ax.set_xlim([y_true.min(), y_true.max()])\n",
    "    ax.set_ylim([y_true.min(), y_true.max()])\n",
    "    ax.set_xlabel(\"Measured\")\n",
    "    ax.set_ylabel(\"Predicted\")\n",
    "    extra = plt.Rectangle(\n",
    "        (0, 0), 0, 0, fc=\"w\", fill=False, edgecolor=\"none\", linewidth=0\n",
    "    )\n",
    "    ax.legend([extra], [scores], loc=\"upper left\")\n",
    "    title = title + \"\\n Evaluation in {:.2f} seconds\".format(elapsed_time)\n",
    "    ax.set_title(title)\n",
    "\n",
    "def plot_data(d, filepath):\n",
    "    plt.scatter(d[:,0], d[:,1])\n",
    "    plt.xlabel('test')\n",
    "    plt.ylabel('predict')\n",
    "    plt.savefig(filepath + '.png')\n",
    "    plt.close()\n",
    "\n",
    "import json\n",
    "from numpy import genfromtxt\n",
    "\n",
    "path = 'results'\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            filepath = os.path.join(root, file)\n",
    "            df = pd.read_csv(filepath)\n",
    "            my_data = genfromtxt(filepath, delimiter=';')\n",
    "            # print(my_data)\n",
    "            plot_data(my_data, filepath.replace('csv','png'))\n",
    "        # if file.endswith('.json'):\n",
    "        #     print(file)\n",
    "        #     dataset = file.replace('.json','')\n",
    "        #     f = open(os.path.join(root, file))\n",
    "        #     data = json.load(f)\n",
    "        #     for key in data:\n",
    "        #         print(key)\n",
    "\n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "            # filepath = os.path.join(root, file)\n",
    "            # df = pd.read_csv(filepath)\n",
    "            # y_res = df.iloc[:,0]\n",
    "            # y_pred = df.iloc[:,1]\n",
    "            # fig, axs = plt.subplots(1,1, figsize=(10,10))\n",
    "            # axs = np.ravel(axs)\n",
    "\n",
    "            # plot_regression_results(\n",
    "            #     ax,\n",
    "            #     y,\n",
    "            #     y_pred,\n",
    "            #     name,\n",
    "            #     (r\"$R^2={:.2f} \\pm {:.2f}$\" + \"\\n\" + r\"$MAE={:.2f} \\pm {:.2f}$\").format(\n",
    "            #         np.mean(score[\"test_r2\"]),\n",
    "            #         np.std(score[\"test_r2\"]),\n",
    "            #         -np.mean(score[\"test_neg_mean_absolute_error\"]),\n",
    "            #         np.std(score[\"test_neg_mean_absolute_error\"]),\n",
    "            #     ),\n",
    "            #     elapsed_time,\n",
    "            # )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# plt.suptitle(\"Single predictors versus stacked predictors\")\n",
    "# plt.tight_layout()\n",
    "# plt.subplots_adjust(top=0.9)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinard.utils import load_csv\n",
    "from benchmark_loop import transform_test_data\n",
    "import preprocessings\n",
    "import numpy as np\n",
    "\n",
    "dumb_set = preprocessings.dumb_and_dumber_set()\n",
    "Xfile = \"data/regression/ALPINE_Calpine_424_Murguzur_RMSE1.36/Xcal.csv.gz\"\n",
    "yfile = \"data/regression/ALPINE_Calpine_424_Murguzur_RMSE1.36/Ycal.csv.gz\"\n",
    "X_train, y_train = load_csv(Xfile, yfile, x_hdr=0, y_hdr=0, sep=\";\")\n",
    "X_train, y_train, X_test, y_test = X_train[0:100], y_train[0:100], X_train[0:100], y_train[0:100]\n",
    "X_test_pp, y_test_pp, transformer_pipeline, y_scaler = transform_test_data(dumb_set, X_train, y_train, X_test, y_test, type=\"augmentation\")\n",
    "\n",
    "print(X_test_pp.shape)\n",
    "sample = X_test_pp[0]\n",
    "print(len(dumb_set))\n",
    "ok = []\n",
    "for i in range(len(dumb_set)-1, -1, -1):\n",
    "    found = False\n",
    "    for j in range(i-1, -1, -1):\n",
    "        if np.allclose(sample[i], sample[j], rtol=10e-3, atol=10e-3):\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        ok.append(dumb_set[i][0])\n",
    "\n",
    "print(len(ok))\n",
    "print(ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def count_columns(file):\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=\";\")\n",
    "        header = next(reader)\n",
    "        header = next(reader)\n",
    "        return len(header), header\n",
    "\n",
    "def walk_directory(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                path = os.path.join(root, file)\n",
    "                columns, header = count_columns(path)\n",
    "                if columns > 2100 and columns < 4000:\n",
    "                    print(header[0:5])\n",
    "                    print(f\"File: {path}, Columns: {columns}\")\n",
    "\n",
    "walk_directory('rawdata/regression') # Replace '.' with the directory path you want to traverse\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynirsENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b09f6e5407ec4329146609a0cb08cbbe4720f97bb26598a93c421b663bd10d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
