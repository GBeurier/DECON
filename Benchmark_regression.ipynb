{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Install dependencies not available on Google Collab.\n",
    "Collab provides numpy, pandas, sklearn, tensorflow, scipy, etc. (see requirements.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinard\n",
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark details\n",
    "\n",
    "The results aggregate the combination of the following trainings configurations:\n",
    "- estimation configuration: [regression, classification]\n",
    "- datasets configurations: [Single Train, Cross validation with 5 folds and 2 repeats, Augmented Single Train]\n",
    "- preprocessing configuration: [flat spectrum, savgol, haar, [small set], [big_set]]\n",
    "- models: \n",
    "   - for all configuration: BACON, BACON-VG, DECON, PLS(components from 1 to 100), XGBoost, LW-PLS\n",
    "   - for single train + small_set : Stack > [ BACON, BACON-VG, DECON, PLS(components from 1 to 100), XGBoost, LW-PLS,\n",
    "   f_PLSRegression,f_AdaBoostRegressor,f_BaggingRegressor,f_ExtraTreesRegressor, f_GradientBoostingRegressor,f_RandomForestRegressor,\n",
    "   f_ARDRegression,f_BayesianRidge,f_ElasticNet,f_ElasticNetCV,f_HuberRegressor, f_LarsCV,f_LassoCV,f_Lasso,f_LassoLars,f_LassoLarsCV,\n",
    "   f_LassoLarsIC,f_LinearRegression,f_OrthogonalMatchingPursuit,f_OrthogonalMatchingPursuitCV, f_PassiveAggressiveRegressor,f_RANSACRegressor,\n",
    "   f_Ridge,f_RidgeCV,f_SGDRegressor,f_TheilSenRegressor,f_GaussianProcessRegressor,f_KNeighborsRegressor, f_Pipeline,f_MLPRegressor,f_LinearSVR,\n",
    "   f_NuSVR,f_SVR,f_DecisionTreeRegressor,f_ExtraTreeRegressor,f_KernelRidge,f_XGBRegressor]\n",
    "\n",
    "We perform training in 2 steps, (1) data transformation and (2) training because the sklearn pipeline does not use test data natively.\n",
    "To change with pinard update in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAST GPU RESET ####\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "# import joblib\n",
    "# import pickle\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics \\\n",
    "    import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error,\\\n",
    "        r2_score, explained_variance_score, mean_squared_log_error, median_absolute_error\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "from data import load_data\n",
    "from preprocessings import transform_test_data\n",
    "from regressors import nn_list, ml_list, get_keras_model\n",
    "from pinard import augmentation, sklearn\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "def get_datasheet(dataset_name, model_name, path, SEED, y_valid, y_pred):\n",
    "    return {\n",
    "        \"model\":model_name, \n",
    "        \"dataset\":dataset_name,\n",
    "        \"seed\":str(SEED),\n",
    "        \"targetRMSE\":str(float(os.path.split(path)[-1].split('_')[-1].split(\"RMSE\")[-1])),\n",
    "        \"RMSE\":str(mean_squared_error(y_valid, y_pred, squared=False)),\n",
    "        \"MAPE\":str(mean_absolute_percentage_error(y_valid, y_pred)),\n",
    "        \"R2\":str(r2_score(y_valid, y_pred)),\n",
    "        \"MAE\":str(mean_absolute_error(y_valid, y_pred)),\n",
    "        \"MSE\":str(mean_squared_error(y_valid, y_pred, squared=True)),\n",
    "        \"MedAE\":str(median_absolute_error(y_valid, y_pred)),\n",
    "        \"EVS\":str(explained_variance_score(y_valid, y_pred)),\n",
    "        # \"MSLE\":str(mean_squared_log_error(y_valid, y_pred)),\n",
    "        \"run\":datetime.datetime.now().strftime(\"%Y-%m-%d  %H:%M:%S\")\n",
    "    }\n",
    "\n",
    "def log_run(dataset_name, model_name, path, SEED, y_valid, y_pred, elapsed_time):\n",
    "    datasheet = get_datasheet(dataset_name, model_name, path, SEED, y_valid, y_pred)\n",
    "    ### Save data\n",
    "    folder = \"results/\" + dataset_name\n",
    "    if not os.path.isdir(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    canon_name = folder + \"/\" + model_name\n",
    "\n",
    "        ## save predictions\n",
    "    np.savetxt(canon_name + '.csv', np.column_stack((y_valid, y_pred)))\n",
    "\n",
    "    ## save main metrics globally\n",
    "    result_file = open(folder + \"/_runs.txt\", \"a\")\n",
    "    log = datasheet[\"RMSE\"] + \"  ---  \" + model_name + \" in \" + time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)) \\\n",
    "        + ' ('+ datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\") + ')\\n'\n",
    "    result_file.write(log)\n",
    "    result_file.close()\n",
    "\n",
    "    ## save pipeline\n",
    "    # joblib.dump(estimator, canon_name + '.pkl')\n",
    "\n",
    "    return datasheet\n",
    "\n",
    "current_estimator = None\n",
    "current_X_test = None\n",
    "current_y_test = None\n",
    "current_path = None\n",
    "\n",
    "def callback_predict(epoch, val_loss):\n",
    "    if current_estimator is None:\n",
    "        return\n",
    "    \n",
    "    y_pred = current_estimator.predict(current_X_test)\n",
    "    res = get_datasheet(\"\", \"\", current_path, -1, current_y_test, y_pred)\n",
    "    print('Epoch:', epoch,'> RMSE:', res['RMSE'], '(', res['targetRMSE'], ') - R²:', res['R2'], ' val_loss', val_loss)\n",
    "\n",
    "def evaluate_pipeline(desc, model_name, data, transformers):\n",
    "    print(\"<\", model_name, \">\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Unpack args\n",
    "    X_train, y_train, X_valid, y_valid = data\n",
    "    dataset_name, path, global_result_file, results, SEED = desc\n",
    "    global current_path\n",
    "    current_path = path\n",
    "    y_scaler, transformer_pipeline, regressor = transformers\n",
    "\n",
    "    # Construct pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('transformation', transformer_pipeline), \n",
    "        (model_name, regressor)\n",
    "    ])\n",
    "\n",
    "    # Fit estimator\n",
    "    estimator = TransformedTargetRegressor(regressor = pipeline, transformer = y_scaler)\n",
    "    global current_estimator\n",
    "    current_estimator = estimator\n",
    "    global current_X_test\n",
    "    current_X_test = X_valid\n",
    "    global current_y_test\n",
    "    current_y_test = y_valid\n",
    "    estimator.fit(X_train, y_train)  \n",
    "    # Evaluate estimator\n",
    "    y_pred = estimator.predict(X_valid)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    datasheet = log_run(dataset_name, model_name, path, SEED, y_valid, y_pred, elapsed_time)\n",
    "    datasheet[\"training_time\"] = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "    results[model_name] = datasheet\n",
    "\n",
    "    # Save results\n",
    "    results = OrderedDict(sorted(results.items(), key=lambda k_v: float(k_v[1]['RMSE'])))\n",
    "    with open(global_result_file, 'w') as fp:\n",
    "        json.dump(results, fp, indent=4)\n",
    "\n",
    "    print(datasheet[\"RMSE\"], \" (\", datasheet[\"targetRMSE\"], \") in\", datasheet[\"training_time\"])\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def benchmark_dataset(path, SEED, preprocessing_list, augment=False):\n",
    "    dataset_name = ('_').join(os.path.split(path)[-1].split('_')[:-1])\n",
    "    print(\"=\"*10, str(dataset_name).upper(), end=\" \")\n",
    "    global_result_file = \"results/\" + dataset_name + '_results.json'\n",
    "    results = {}\n",
    "    if os.path.isfile(global_result_file):\n",
    "        with open(global_result_file) as json_file:\n",
    "            results = json.load(json_file)\n",
    "   \n",
    "    desc = (dataset_name, path, global_result_file, results, SEED)\n",
    "\n",
    "    X, y, X_valid, y_valid = load_data(path)\n",
    "    print(X.shape, y.shape, X_valid.shape, y_valid.shape, \"=\"*10)\n",
    "    \n",
    "\n",
    "    #########################\n",
    "    ### SINGLE RUN TRAINING\n",
    "    X_train, y_train, X_test, y_test = X, y, X_valid, y_valid\n",
    "\n",
    "    if(augment):\n",
    "        augmentation_pipeline = sklearn.SampleAugmentation([\n",
    "            (2, 'rot_tr', augmentation.Rotate_Translate()),\n",
    "            (1, 'rd_mult', augmentation.Random_X_Operation()),\n",
    "            (1, 'simpl', augmentation.Random_Spline_Addition())\n",
    "        ])\n",
    "        print(X_train.shape, y_train.shape)\n",
    "        X_train, y_train = augmentation_pipeline.transform(X_train, y_train)\n",
    "        print(X_train.shape, y_train.shape)\n",
    "\n",
    "    data = (X_train, y_train, X_valid, y_valid)\n",
    "    for preprocessing in preprocessing_list:            \n",
    "        ##### DEEP LEARNING #####\n",
    "        X_test_pp, y_test_pp, transformer_pipeline, y_scaler = transform_test_data(preprocessing, X_train, y_train, X_test, y_test, type=\"augmentation\")\n",
    "        for model_desc in nn_list():\n",
    "            model_name = model_desc.__name__ + \"-\" + preprocessing.__name__ + \"-\" + str(SEED)\n",
    "            if os.path.isfile(  \"results/\" + dataset_name + \"/\" + model_name + '.csv'):\n",
    "                # print(\"Skipping\", model_name)\n",
    "                continue\n",
    "            \n",
    "            batch_size = 20\n",
    "            if preprocessing.__name__ == \"dumb_set\":\n",
    "                batch_size = 3\n",
    "            regressor = get_keras_model(dataset_name + '_' + model_name, model_desc, 4096, batch_size, X_test_pp, y_test_pp, transfer=True, callback_func=callback_predict, verbose=0, seed=SEED)\n",
    "            transformers = (y_scaler, transformer_pipeline, regressor)\n",
    "            evaluate_pipeline(desc, model_name, data, transformers)\n",
    "        \n",
    "        # ##### MACHINE LEARNING #####\n",
    "        # X_test_pp, y_test_pp, transformer_pipeline, y_scaler = transform_test_data(preprocessing, X_train, y_train, X_test, y_test, type=\"union\")\n",
    "        # for regressor, mdl_name in ml_list(SEED, X_test_pp, y_test_pp):\n",
    "        #     model_name = mdl_name + \"-\" + preprocessing.__name__ + \"-\" + str(SEED)\n",
    "        #     if os.path.isfile(  \"results/\" + dataset_name + \"/\" + model_name + '.csv'):\n",
    "        #        # print(\"Skipping\", model_name)\n",
    "        #         continue\n",
    "        #     transformers = (y_scaler, transformer_pipeline, regressor)\n",
    "        #     evaluate_pipeline(desc, model_name, data, transformers)\n",
    "\n",
    "    #########################\n",
    "\n",
    "\n",
    "\n",
    "    #########################\n",
    "    # ### CROSS VALIDATION TRAINING\n",
    "    # cv_predictions = {}\n",
    "    # for preprocessing in preprocessing_list():\n",
    "    #     fold = RepeatedKFold(n_splits=5, n_repeats=2, random_state=SEED)\n",
    "    #     fold_index = 0\n",
    "    #     for train_index, test_index in fold.split(X):\n",
    "    #         X_train, y_train, X_test, y_test = X[train_index], y[train_index], X[test_index], y[test_index]\n",
    "    #         data = (X_train, y_train, X_valid, y_valid)\n",
    "            \n",
    "    #         ##### DEEP LEARNING #####\n",
    "    #         X_test_pp, y_test_pp, transformer_pipeline, y_scaler = transform_test_data(preprocessing, X_train, y_train, X_test, y_test, type=\"augmentation\")\n",
    "    #         for model_desc in nn_list():\n",
    "    #             model_name = model_desc.__name__ + \"-\" + preprocessing.__name__  + \"-\" + str(SEED)\n",
    "    #             fold_name = model_name + \"-F\" + str(fold_index)\n",
    "    #             if os.path.isfile(  \"results/\" + dataset_name + \"/\" + fold_name + '.csv'):\n",
    "    #                # print(\"Skipping\", model_name)\n",
    "    #                 continue\n",
    "    #             regressor = get_keras_model(dataset_name + '_' + fold_name, model_desc, 7500, 750, X_test_pp, y_test_pp, verbose=0, seed=SEED)\n",
    "    #             y_pred = evaluate_pipeline(desc, fold_name, data, (y_scaler, transformer_pipeline, regressor))\n",
    "    #             cv_predictions[model_name] = cv_predictions[model_name] + y_pred if model_name in cv_predictions else y_pred\n",
    "            \n",
    "    #         ##### MACHINE LEARNING #####\n",
    "    #         X_test_pp, y_test_pp, transformer_pipeline, y_scaler = transform_test_data(preprocessing, X_train, y_train, X_test, y_test, type=\"union\")\n",
    "    #         for regressor, mdl_name in ml_list(SEED, X_test_pp, y_test_pp):\n",
    "    #             model_name = mdl_name + \"-\" + preprocessing.__name__ + \"-\" + str(SEED)\n",
    "    #             fold_name = model_name + \"-F\" + str(fold_index)\n",
    "    #             if os.path.isfile(  \"results/\" + dataset_name + \"/\" + fold_name + '.csv'):\n",
    "    #              #  print(\"Skipping\", model_name)\n",
    "    #                 continue\n",
    "    #             y_pred = evaluate_pipeline(desc, fold_name, data, (y_scaler, transformer_pipeline, regressor))\n",
    "    #             cv_predictions[model_name] = cv_predictions[model_name] + y_pred if model_name in cv_predictions else y_pred\n",
    "                \n",
    "    #         fold_index +=1\n",
    "\n",
    "    # for key, val in cv_predictions.items():\n",
    "    #     y_pred = val / fold.get_n_splits()\n",
    "    #     datasheet = get_datasheet(dataset_name, key, path, SEED, y_valid, y_pred)\n",
    "    #     results[key +\"_CV\"] = datasheet\n",
    "    #\n",
    "    # results = OrderedDict(sorted(results.items(), key=lambda k_v: float(k_v[1]['RMSE'])))\n",
    "    # with open(global_result_file, 'w') as fp:\n",
    "    #     json.dump(results, fp, indent=4)\n",
    "\n",
    "    # #########################\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "========== MEAT_FATE1_215_BORGGAARD (172, 100) (172,) (8, 100) (8,) ==========\n",
      "< decon-decon_set-31441 >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 > RMSE: 23.853296 ( 2.33 ) - R²: -440.2343198841712  val_loss 0.6396484375\n",
      "Epoch: 42 > RMSE: 23.34785 ( 2.33 ) - R²: -421.7331550854223  val_loss 0.6259765625\n",
      "Epoch: 43 > RMSE: 21.077036 ( 2.33 ) - R²: -343.50185931758165  val_loss 0.56494140625\n",
      "Epoch: 44 > RMSE: 20.060656 ( 2.33 ) - R²: -311.07772286978667  val_loss 0.5380859375\n",
      "Epoch: 45 > RMSE: 19.321972 ( 2.33 ) - R²: -288.5178693401477  val_loss 0.51806640625\n",
      "Epoch: 62 > RMSE: 19.0025 ( 2.33 ) - R²: -279.02321781107247  val_loss 0.509765625\n",
      "Epoch: 63 > RMSE: 18.825274 ( 2.33 ) - R²: -273.82426283706  val_loss 0.5048828125\n",
      "Epoch: 64 > RMSE: 17.701094 ( 2.33 ) - R²: -241.98121829018476  val_loss 0.474853515625\n",
      "Epoch: 65 > RMSE: 15.357153 ( 2.33 ) - R²: -181.89166331983148  val_loss 0.41162109375\n",
      "Epoch: 66 > RMSE: 12.877735 ( 2.33 ) - R²: -127.60311283606262  val_loss 0.34521484375\n",
      "Epoch: 71 > RMSE: 12.307203 ( 2.33 ) - R²: -116.46033795346888  val_loss 0.330322265625\n",
      "Epoch: 87 > RMSE: 7.5289607 ( 2.33 ) - R²: -42.95847174134495  val_loss 0.2020263671875\n",
      "Epoch: 88 > RMSE: 5.3304725 ( 2.33 ) - R²: -21.034536365107286  val_loss 0.142822265625\n",
      "Epoch: 89 > RMSE: 5.293243 ( 2.33 ) - R²: -20.727818856485474  val_loss 0.141845703125\n",
      "Epoch: 91 > RMSE: 5.293243 ( 2.33 ) - R²: -20.727818856485474  val_loss 0.1416015625\n",
      "Saved best 0.1416 at epoch 91\n",
      "5.293243  ( 2.33 ) in 00:02:05\n",
      "< decon-dumb_set-31441 >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 > RMSE: 23.88451 ( 2.33 ) - R²: -441.38988315740914  val_loss 0.63970947265625\n",
      "Epoch: 16 > RMSE: 6.8204947 ( 2.33 ) - R²: -35.07482974181507  val_loss 0.618896484375\n",
      "Epoch: 19 > RMSE: 10.246696 ( 2.33 ) - R²: -80.4217101598712  val_loss 0.60107421875\n",
      "Epoch: 23 > RMSE: 5.764067 ( 2.33 ) - R²: -24.76502803224025  val_loss 0.265960693359375\n",
      "Saved best 0.2660 at epoch 23\n",
      "5.764067  ( 2.33 ) in 00:05:48\n",
      "========== MEAT_FATE2_215_BORGGAARD (172, 100) (172,) (17, 100) (17,) ==========\n",
      "< decon-decon_set-31441 >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 > RMSE: 14.131049 ( 0.44 ) - R²: -23.782662256934785  val_loss 0.37939453125\n",
      "Epoch: 1 > RMSE: 14.100437 ( 0.44 ) - R²: -23.67540642896875  val_loss 0.3779296875\n",
      "Epoch: 2 > RMSE: 14.008619 ( 0.44 ) - R²: -23.355094865203732  val_loss 0.37548828125\n",
      "Epoch: 3 > RMSE: 13.886236 ( 0.44 ) - R²: -22.931405675540297  val_loss 0.372314453125\n",
      "Epoch: 4 > RMSE: 13.611047 ( 0.44 ) - R²: -21.992285863913356  val_loss 0.364990234375\n",
      "Epoch: 5 > RMSE: 13.03094 ( 0.44 ) - R²: -20.07417724397539  val_loss 0.349365234375\n",
      "Epoch: 6 > RMSE: 11.814096 ( 0.44 ) - R²: -16.32208299642466  val_loss 0.31640625\n",
      "Epoch: 7 > RMSE: 9.555612 ( 0.44 ) - R²: -10.332248610958542  val_loss 0.256103515625\n",
      "Epoch: 8 > RMSE: 7.8434315 ( 0.44 ) - R²: -6.635039532892619  val_loss 0.209716796875\n",
      "Epoch: 20 > RMSE: 7.813666 ( 0.44 ) - R²: -6.577200356208997  val_loss 0.20947265625\n",
      "Epoch: 30 > RMSE: 7.3798256 ( 0.44 ) - R²: -5.759138163557929  val_loss 0.19775390625\n",
      "Epoch: 32 > RMSE: 6.0134053 ( 0.44 ) - R²: -3.4878684702502385  val_loss 0.1611328125\n",
      "Epoch: 34 > RMSE: 5.2546825 ( 0.44 ) - R²: -2.426826549687042  val_loss 0.1407470703125\n",
      "Epoch: 46 > RMSE: 4.9466844 ( 0.44 ) - R²: -2.0368791633772703  val_loss 0.1326904296875\n",
      "Epoch: 48 > RMSE: 4.55533 ( 0.44 ) - R²: -1.5753647621820823  val_loss 0.12213134765625\n",
      "Epoch: 51 > RMSE: 3.8639274 ( 0.44 ) - R²: -0.8529216381062397  val_loss 0.10333251953125\n",
      "Epoch: 54 > RMSE: 3.769608 ( 0.44 ) - R²: -0.7635650307774999  val_loss 0.10064697265625\n",
      "Epoch: 69 > RMSE: 3.0809267 ( 0.44 ) - R²: -0.1780450439201824  val_loss 0.08258056640625\n",
      "Epoch: 77 > RMSE: 2.5607271 ( 0.44 ) - R²: 0.18618494342475367  val_loss 0.06890869140625\n",
      "Epoch: 78 > RMSE: 2.2043824 ( 0.44 ) - R²: 0.39692268499398486  val_loss 0.059173583984375\n",
      "Epoch: 154 > RMSE: 2.1355424 ( 0.44 ) - R²: 0.434001158738641  val_loss 0.0574951171875\n",
      "Epoch: 166 > RMSE: 2.0983884 ( 0.44 ) - R²: 0.4535241735401505  val_loss 0.0562744140625\n",
      "Saved best 0.0563 at epoch 166\n",
      "2.0983884  ( 0.44 ) in 00:02:32\n",
      "< decon-dumb_set-31441 >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 > RMSE: 14.131049 ( 0.44 ) - R²: -23.782662256934785  val_loss 0.37181180715560913\n",
      "Epoch: 1 > RMSE: 14.039223 ( 0.44 ) - R²: -23.461622941971047  val_loss 0.36935603618621826\n",
      "Epoch: 2 > RMSE: 13.397183 ( 0.44 ) - R²: -21.275433583221904  val_loss 0.35187843441963196\n",
      "Epoch: 3 > RMSE: 7.4950795 ( 0.44 ) - R²: -5.971906650345718  val_loss 0.1876920759677887\n",
      "Epoch: 6 > RMSE: 5.8275046 ( 0.44 ) - R²: -3.2146771952822384  val_loss 0.14877767860889435\n",
      "Epoch: 12 > RMSE: 2.6190267 ( 0.44 ) - R²: 0.14870727961732588  val_loss 0.10953117907047272\n",
      "Epoch: 13 > RMSE: 3.7868316 ( 0.44 ) - R²: -0.7797177365234425  val_loss 0.09331467747688293\n",
      "Epoch: 14 > RMSE: 3.915358 ( 0.44 ) - R²: -0.9025764400470311  val_loss 0.0902772769331932\n",
      "Epoch: 15 > RMSE: 4.6848054 ( 0.44 ) - R²: -1.723844115125854  val_loss 0.06366146355867386\n",
      "Epoch: 47 > RMSE: 4.1429334 ( 0.44 ) - R²: -1.1301739741356758  val_loss 0.06247038021683693\n",
      "Epoch: 48 > RMSE: 4.1235986 ( 0.44 ) - R²: -1.1103372189732532  val_loss 0.060897380113601685\n",
      "Saved best 0.0609 at epoch 48\n",
      "4.1235986  ( 0.44 ) in 00:06:24\n",
      "========== MEAT_FAT_215_BORGGAARD (172, 100) (172,) (43, 100) (43,) ==========\n",
      "< decon-decon_set-31441 >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 > RMSE: 11.266404 ( 0.65 ) - R²: -0.26715438069405906  val_loss 0.2986464500427246\n",
      "Epoch: 1 > RMSE: 11.2520895 ( 0.65 ) - R²: -0.2639364422025159  val_loss 0.29820358753204346\n",
      "Epoch: 2 > RMSE: 11.2378435 ( 0.65 ) - R²: -0.2607380115108324  val_loss 0.29739734530448914\n",
      "Epoch: 3 > RMSE: 11.19552 ( 0.65 ) - R²: -0.2512596998129717  val_loss 0.2960687577724457\n",
      "Epoch: 4 > RMSE: 11.099218 ( 0.65 ) - R²: -0.22982605485733876  val_loss 0.29320719838142395\n",
      "Epoch: 5 > RMSE: 10.880115 ( 0.65 ) - R²: -0.1817505212770334  val_loss 0.2872229218482971\n",
      "Epoch: 6 > RMSE: 10.528209 ( 0.65 ) - R²: -0.10654177177692792  val_loss 0.27605491876602173\n",
      "Epoch: 7 > RMSE: 10.069968 ( 0.65 ) - R²: -0.012313502300453694  val_loss 0.2601630687713623\n",
      "Epoch: 8 > RMSE: 10.084217 ( 0.65 ) - R²: -0.015180414849607304  val_loss 0.25647255778312683\n",
      "Epoch: 9 > RMSE: 10.009507 ( 0.65 ) - R²: -0.0001939551875531631  val_loss 0.2562738358974457\n",
      "Epoch: 39 > RMSE: 9.625812 ( 0.65 ) - R²: 0.07501725422948435  val_loss 0.251953125\n",
      "Epoch: 41 > RMSE: 9.575706 ( 0.65 ) - R²: 0.08462195370665826  val_loss 0.25103333592414856\n",
      "Epoch: 43 > RMSE: 9.472253 ( 0.65 ) - R²: 0.10429411510978837  val_loss 0.2502554953098297\n",
      "Epoch: 44 > RMSE: 9.419156 ( 0.65 ) - R²: 0.1143077515028188  val_loss 0.24546919763088226\n",
      "Epoch: 48 > RMSE: 9.336611 ( 0.65 ) - R²: 0.12976341862887586  val_loss 0.24545784294605255\n",
      "Epoch: 50 > RMSE: 8.895151 ( 0.65 ) - R²: 0.2101119619360179  val_loss 0.2333076000213623\n",
      "Epoch: 51 > RMSE: 8.174624 ( 0.65 ) - R²: 0.3328946535167645  val_loss 0.21242505311965942\n",
      "Epoch: 53 > RMSE: 8.068651 ( 0.65 ) - R²: 0.35007878168038853  val_loss 0.207968071103096\n",
      "Epoch: 54 > RMSE: 8.088623 ( 0.65 ) - R²: 0.346857395888712  val_loss 0.20665083825588226\n",
      "Epoch: 55 > RMSE: 7.570634 ( 0.65 ) - R²: 0.42783227737478935  val_loss 0.19661268591880798\n",
      "Epoch: 59 > RMSE: 7.5232315 ( 0.65 ) - R²: 0.4349749635811847  val_loss 0.19317200779914856\n",
      "Epoch: 60 > RMSE: 7.2754636 ( 0.65 ) - R²: 0.47157881203429963  val_loss 0.1861884593963623\n",
      "Epoch: 67 > RMSE: 5.630119 ( 0.65 ) - R²: 0.6835581308571611  val_loss 0.14735306799411774\n",
      "Epoch: 68 > RMSE: 5.07243 ( 0.65 ) - R²: 0.7431432177003938  val_loss 0.13331498205661774\n",
      "Epoch: 69 > RMSE: 4.2129254 ( 0.65 ) - R²: 0.8228152389262267  val_loss 0.10996264219284058\n",
      "Epoch: 71 > RMSE: 3.8363786 ( 0.65 ) - R²: 0.8530729561416286  val_loss 0.1001487523317337\n",
      "Epoch: 72 > RMSE: 3.6860151 ( 0.65 ) - R²: 0.8643645862046212  val_loss 0.09774567186832428\n",
      "Epoch: 96 > RMSE: 3.196224 ( 0.65 ) - R²: 0.8980157107064223  val_loss 0.08216503262519836\n",
      "Epoch: 163 > RMSE: 3.1119153 ( 0.65 ) - R²: 0.9033249487579893  val_loss 0.08163558691740036\n",
      "Epoch: 196 > RMSE: 2.6017416 ( 0.65 ) - R²: 0.9324248319985983  val_loss 0.06955169141292572\n",
      "Epoch: 198 > RMSE: 2.6377597 ( 0.65 ) - R²: 0.9305408778464737  val_loss 0.06880791485309601\n",
      "Epoch: 206 > RMSE: 2.1922607 ( 0.65 ) - R²: 0.9520218746736895  val_loss 0.058510005474090576\n",
      "Epoch: 210 > RMSE: 2.001519 ( 0.65 ) - R²: 0.9600075244555679  val_loss 0.05365487188100815\n",
      "Saved best 0.0537 at epoch 210\n",
      "2.001519  ( 0.65 ) in 00:02:52\n",
      "< decon-dumb_set-31441 >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 > RMSE: 11.266404 ( 0.65 ) - R²: -0.26715438069405906  val_loss 0.27560141682624817\n",
      "Epoch: 1 > RMSE: 11.140067 ( 0.65 ) - R²: -0.23889492524409195  val_loss 0.27275121212005615\n",
      "Epoch: 2 > RMSE: 10.30508 ( 0.65 ) - R²: -0.060136118106337344  val_loss 0.25472384691238403\n",
      "Epoch: 3 > RMSE: 10.191155 ( 0.65 ) - R²: -0.036825668505932274  val_loss 0.23789304494857788\n",
      "Epoch: 5 > RMSE: 10.01072 ( 0.65 ) - R²: -0.0004364712574516094  val_loss 0.23747147619724274\n",
      "Epoch: 6 > RMSE: 9.934973 ( 0.65 ) - R²: 0.014646004455420414  val_loss 0.23025228083133698\n",
      "Epoch: 16 > RMSE: 4.2544694 ( 0.65 ) - R²: 0.8193034889333736  val_loss 0.1885787546634674\n",
      "Epoch: 17 > RMSE: 3.3642476 ( 0.65 ) - R²: 0.8870113721770204  val_loss 0.15780071914196014\n",
      "Epoch: 30 > RMSE: 3.6038568 ( 0.65 ) - R²: 0.8703436298736184  val_loss 0.15297822654247284\n",
      "Epoch: 46 > RMSE: 3.2515001 ( 0.65 ) - R²: 0.8944577303158057  val_loss 0.11863744258880615\n",
      "Epoch: 72 > RMSE: 4.386991 ( 0.65 ) - R²: 0.8078712786897292  val_loss 0.10601948946714401\n",
      "Epoch: 96 > RMSE: 3.6527908 ( 0.65 ) - R²: 0.8667987088543255  val_loss 0.09768889844417572\n",
      "Epoch: 103 > RMSE: 3.7164838 ( 0.65 ) - R²: 0.8621129774361218  val_loss 0.0833461657166481\n",
      "Saved best 0.0833 at epoch 103\n",
      "3.7164838  ( 0.65 ) in 00:07:56\n",
      "========== RICE_REDOX_3693_SENSEEN (2769, 256) (2769,) (922, 256) (922,) ==========\n",
      "< decon-decon_set-31441 >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 > RMSE: 28.076353 ( 10.267 ) - R²: -0.26147596678947127  val_loss 0.1434907466173172\n",
      "Epoch: 1 > RMSE: 25.065573 ( 10.267 ) - R²: -0.0054324354945487485  val_loss 0.12340858578681946\n",
      "Epoch: 4 > RMSE: 21.084618 ( 10.267 ) - R²: 0.2885751196296703  val_loss 0.10725518316030502\n",
      "Epoch: 8 > RMSE: 18.098942 ( 10.267 ) - R²: 0.47579154681788194  val_loss 0.09189723432064056\n",
      "Epoch: 9 > RMSE: 17.888037 ( 10.267 ) - R²: 0.4879375079614082  val_loss 0.09036963433027267\n",
      "Epoch: 13 > RMSE: 16.931723 ( 10.267 ) - R²: 0.5412247960730328  val_loss 0.08581516146659851\n",
      "Epoch: 20 > RMSE: 16.17534 ( 10.267 ) - R²: 0.5812984973334095  val_loss 0.0823463574051857\n",
      "Epoch: 102 > RMSE: 15.737817 ( 10.267 ) - R²: 0.6036429729152074  val_loss 0.0805252343416214\n",
      "Saved best 0.0805 at epoch 102\n",
      "15.737817  ( 10.267 ) in 00:16:46\n",
      "< decon-dumb_set-31441 >\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 > RMSE: 25.173283 ( 10.267 ) - R²: -0.014091846263132313  val_loss 0.11260968446731567\n",
      "Epoch: 3 > RMSE: 18.525513 ( 10.267 ) - R²: 0.4507904956410106  val_loss 0.11185597628355026\n",
      "Epoch: 36 > RMSE: 16.85721 ( 10.267 ) - R²: 0.5452538512021413  val_loss 0.10657645761966705\n",
      "Epoch: 45 > RMSE: 16.465078 ( 10.267 ) - R²: 0.5661643666321429  val_loss 0.10575670748949051\n",
      "epoch 00163\r"
     ]
    }
   ],
   "source": [
    "## Browse path and launch benchmark for every folders\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "from preprocessings import preprocessing_list\n",
    "\n",
    "rootdir = Path('data2/regression')\n",
    "folder_list = [f for f in rootdir.glob('**/*') if f.is_dir()]\n",
    "\n",
    "SEED = ord('D') + 31373\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# (preprocessing_list, nn_run, nn_cv, ml_single, ml_cv)\n",
    "\n",
    "# benchmark_dataset(\"data2/regression/ALPINE_Calpine_424_Murguzur_RMSE1.36\", SEED, preprocessing_list())\n",
    "# benchmark_dataset(\"data2/regression/Cassava_TBC_3556_Davrieux_RMSE1.02\", SEED, preprocessing_list(), augment=True)\n",
    "# benchmark_dataset(\"data2/regression/ALPINE_Calpine_424_Murguzur_RMSE1.36\", SEED, preprocessing_list())\n",
    "\n",
    "for folder in folder_list:\n",
    "    # print(ord(str(folder)[17]), ord('A'), ord('M'))\n",
    "    if ord(str(folder)[17]) < ord(\"L\") or ord(str(folder)[17]) > ord(\"M\"):\n",
    "        continue\n",
    "    benchmark_dataset(folder, SEED, preprocessing_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pynirsENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b09f6e5407ec4329146609a0cb08cbbe4720f97bb26598a93c421b663bd10d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
